# Dataset Manager gFresh

CLI para analizar datos operativos, generar informes y gestionar el ciclo de vida de datasets (creaciÃ³n, fusiÃ³n, resumen y registro en S3).

## ğŸ¯ Objetivo

Automatizar selecciÃ³n y preparaciÃ³n de imÃ¡genes de producciÃ³n para entrenar y versionar modelos de clasificaciÃ³n retail.

## ğŸ—ï¸ Estructura

`dataset_manager/` contiene los mÃ³dulos internos (extracciÃ³n, anÃ¡lisis, creaciÃ³n de datasets, descarga de imÃ¡genes y reporting) expuestos vÃ­a `main.py`.

## ğŸš€ Funcionalidades

### ğŸ” AnÃ¡lisis

- **DetecciÃ³n inteligente** de clases nuevas o no entrenadas
- **AnÃ¡lisis de devices** con mÃ©tricas de rendimiento individuales
- **IdentificaciÃ³n automÃ¡tica** de referencias sin `label_id` asignado
- **CÃ¡lculo de mÃ©tricas** de % Ok del sistema y % Ok del modelo
- **VerificaciÃ³n de consistencia** con alertas automÃ¡ticas
- **AnÃ¡lisis de dispositivos** con seguimiento de performance por device

### ğŸ› ï¸ Procesamiento

- **Descarga automÃ¡tica** de datos de inferencia desde Elasticsearch
- **ExtracciÃ³n completa** de tablas `reference`, `label` y `model` desde BD
- **IdentificaciÃ³n automÃ¡tica** del modelo activo en producciÃ³n
- **Filtrado inteligente** por nÃºmero mÃ­nimo de apariciones
- **Soporte para mÃºltiples deployments** con gestiÃ³n independiente

### ğŸ“ˆ Informes

**Excel principal** con mÃºltiples pestaÃ±as especializadas:

- **`Resumen`**: Dashboard ejecutivo con mÃ©tricas clave
- **`Datos_Elasticsearch`**: Datos raw de Elastic con toda la informaciÃ³n
- **`References`**: AnÃ¡lisis completo de referencias con porcentajes Ok
- **`Devices`**: AnÃ¡lisis detallado por device con mÃ©tricas individuales
- **`Labels`**: InformaciÃ³n de etiquetas y clasificaciones
- **`Model_Data`**: InformaciÃ³n del modelo expandida y configuraciÃ³n
- **`Consistencia`**: Verificaciones de integridad y alertas

### ğŸ–¼ï¸ RevisiÃ³n de ImÃ¡genes

**Nueva funcionalidad avanzada para descarga selectiva de imÃ¡genes:**

- **Descarga automÃ¡tica** de imÃ¡genes para referencias marcadas para revisiÃ³n
- **Descarga de imÃ¡genes de devices** para anÃ¡lisis de rendimiento por dispositivo
- **OrganizaciÃ³n inteligente** por carpetas:
  - `productos/` â†’ ImÃ¡genes de referencias de productos
  - `devices/{device_id}/` â†’ ImÃ¡genes especÃ­ficas por device
- **Logs detallados** en hojas Excel separadas:
  - `revisar_imagenes_bajadas` â†’ Log detallado de referencias
  - `devices_imagenes_bajadas` â†’ Log detallado de devices
- **Modo dry-run** para simulaciÃ³n sin descarga real
- **SelecciÃ³n inteligente** de transacciones representativas

### ğŸ”„ Procesos

- **Sistema de procesos independientes** con metadata completa
- **Tracking automÃ¡tico** de configuraciones y resultados
- **Logs detallados** por proceso con timestamps
- **ReutilizaciÃ³n** de configuraciones y datos entre sesiones

## ğŸ“¦ InstalaciÃ³n

```bash
python -m venv venv
./venv/Scripts/activate   # Windows
pip install -r requirements.txt
cp .env.example .env  # Rellenar credenciales
```

### Credenciales

1. **Variables de entorno (.env):**

```bash
# Copiar archivo de ejemplo
cp .env.example .env

# Editar con credenciales reales
DB_PROD_RO_HOST=your_mysql_host
DB_PROD_RO_USER=your_readonly_user
DB_PROD_RO_PASSWORD=your_readonly_password
DB_PROD_RO_DATABASE=your_database_name
```

1. **Elasticsearch:**

Crear `config/credentials/credentials_elastic_prod.json`:

```json
{
    "host": "tu-cluster.elasticsearch.com",
    "port": 9243,
    "verify_certs": true,
    "username": "tu_usuario",
    "password": "tu_password",
    "use_ssl": true
}
```

1. **AWS S3:**

Las credenciales de S3 se configuran automÃ¡ticamente desde el archivo de Elasticsearch.

## ğŸ–¥ï¸ Uso RÃ¡pido

```bash
# Activar entorno virtual
./venv/Scripts/activate  # Windows
source venv/bin/activate # Linux/Mac

# Descarga y genera Excel del deployment 130 (Ãºltimos 30 dÃ­as)
python main.py download_info 130 --days-back 30

# Crear dataset (estructura de carpetas) a partir del proceso activo
python main.py create_dataset

# Resumen del dataset
python main.py summary_dataset -d dataset_130_010825_v1

# Registrar (ZIP + S3 + CSV global)
python main.py register_dataset -d dataset_130_010825_v1

# Fusionar varios datasets
python main.py merge_datasets

# Estructura de carpetas hoja
python main.py folder_structure
```

## ğŸ“œ Comandos

| Comando | DescripciÃ³n | ParÃ¡metros clave |
|---------|-------------|------------------|
| `analyze <deployment_id>` | Extrae y analiza (sin Excel, sin imÃ¡genes). | `--days-back`, `--confidence`, `--min-appearances` |
| `download_info <deployment_id>` | Pipeline completo (datos + Excel). | `--days-back`, `--process-name`, filtros |
| `active-process` | Ver / listar / set / limpiar proceso activo. | `--list`, `--clear`, `--set` |
| `status` | Estado y configuraciÃ³n. |  |
| `review_images` | Descarga imÃ¡genes (referencias + devices) marcadas. | `--dry-run`, `-e <excel>` |
| `create_dataset` | Construye dataset (clase/label_id) desde Excel del proceso. | `--fast`, lÃ­mites, `--no-filter-used` |
| `folder_structure` | CSV con carpetas hoja y conteo de imÃ¡genes. | `--input`, `--output` |
| `merge_datasets` | Une varios datasets en uno nuevo. | interactivo |
| `summary_dataset` | Genera `_summary_<dataset>.csv` cruzando imÃ¡genes con Excel. | `-d <dataset>` |
| `register_dataset` | ZIP + S3 + registro CSV + opcional subir datasets.csv a S3. | `-d`, `--s3-base`, `--registry-csv` |

Comandos eliminados: `crear_dataset`, `review_devices`, `folder`, `validate-config`, `process`.

### Ejemplos

```bash
# Ajustando confianza y nombre de proceso
python main.py download_info 130 --days-back 45 --confidence 0.78 --process-name dataset_130_aug_v2

# Dataset modo rÃ¡pido
python main.py create_dataset --fast --limit-refs 25 --images-per-ref 12

# No filtrar transacciones ya usadas
python main.py create_dataset --no-filter-used

# Resumen y registro sin regenerar ZIP ni reemplazar S3
python main.py summary_dataset -d dataset_130_aug_v2
python main.py register_dataset -d dataset_130_aug_v2
```

## ğŸ“Š Outputs

### Directorios del Sistema

```text
output/
â”œâ”€â”€ processes/                 # Procesos independientes
â”‚   â””â”€â”€ dataset_{id}_{date}_v1/
â”‚       â”œâ”€â”€ reports/          # Archivos Excel generados
â”‚       â”œâ”€â”€ images/           # ImÃ¡genes descargadas
â”‚       â”‚   â”œâ”€â”€ productos/    # ImÃ¡genes de referencias
â”‚       â”‚   â””â”€â”€ devices/      # ImÃ¡genes por device
â”‚       â”œâ”€â”€ data/            # Datos procesados
â”‚       â”œâ”€â”€ logs/            # Logs detallados
â”‚       â””â”€â”€ process_metadata.json
â””â”€â”€ legacy/                   # Archivos antiguos (compatibilidad)
```

### Archivos Excel Generados

#### Archivo Principal: `dataset_{deployment_id}_{timestamp}.xlsx`

**PestaÃ±as principales:**

- **`Resumen`**: MÃ©tricas ejecutivas y KPIs principales
- **`Datos_Elasticsearch`**: Dataset completo con 26K+ registros
- **`References`**: 74 referencias analizadas con mÃ©tricas
- **`Devices`**: 9 devices con anÃ¡lisis individual de rendimiento
- **`Labels`**: Clasificaciones y etiquetas del modelo
- **`Model_Data`**: ConfiguraciÃ³n del modelo activo
- **`Consistencia`**: Validaciones e inconsistencias detectadas

**PestaÃ±as de seguimiento de imÃ¡genes:**

- **`revisar_imagenes_bajadas`**: Log detallado de imÃ¡genes de productos
- **`devices_imagenes_bajadas`**: Log detallado de imÃ¡genes de devices

#### Estructura de Datos en PestaÃ±as

**References (ejemplo):**

- `reference_name`: CÃ³digo de la referencia
- `label_name`: Nombre de la etiqueta asociada
- `total_transactions`: Total de transacciones
- `ok_percentage`: % de aciertos del sistema
- `model_ok_percentage`: % de aciertos del modelo
- `revisar_imagenes`: Marca para descarga de imÃ¡genes
- MÃ©tricas adicionales por top1, top2, top3

**Devices (ejemplo):**

- `device_id`: ID Ãºnico del dispositivo
- `device_name`: Nombre del dispositivo
- `total_transactions`: Transacciones procesadas
- `ok_percentage`: Rendimiento del dispositivo
- `revisar_imagenes`: Marca para descarga de imÃ¡genes
- MÃ©tricas de precisiÃ³n y errores

## âš™ï¸ ConfiguraciÃ³n (extracto)

### Variables de Entorno (.env)

```bash
# Base de datos MySQL (Solo lectura) - REQUERIDO
DB_PROD_RO_HOST=your_mysql_host
DB_PROD_RO_USER=your_readonly_user
DB_PROD_RO_PASSWORD=your_readonly_password
DB_PROD_RO_DATABASE=your_database_name
DB_PROD_RO_PORT=3306

# ConfiguraciÃ³n opcional
LOG_LEVEL=INFO
OUTPUT_BASE_DIR=./output
```

### ConfiguraciÃ³n de Descarga de ImÃ¡genes

La configuraciÃ³n se maneja automÃ¡ticamente, pero se puede personalizar:

```yaml
image_review:
  num_imagenes_revision: 5              # ImÃ¡genes por referencia/device
  tipo_transacciones: "ambas"           # correctas|incorrectas|ambas
  clear_output_folder: true             # Limpiar carpeta antes de descargar
  tipo_imagenes_bajar: "clase_y_similares"  # Tipos de productos a descargar
  s3_bucket: "grabit-data"              # Bucket de S3
  s3_region: "eu-west-2"                # RegiÃ³n de S3
```

## ğŸ”§ Flujo RecomENDADO

### 1. AnÃ¡lisis Inicial

```bash
# Generar anÃ¡lisis completo
python main.py download_info 125 --days-back 7

# Revisar archivo Excel generado
# Marcar referencias/devices para revisiÃ³n
```

### 2. RevisiÃ³n de ImÃ¡genes

```bash
# Simular descarga primero
python main.py review_images --dry-run

# Descargar imÃ¡genes reales
python main.py review_images

# Revisar imÃ¡genes descargadas en:
# output/processes/dataset_125_*/images/productos/
# output/processes/dataset_125_*/images/devices/
```

### 3. AnÃ¡lisis de Resultados

- Revisar logs detallados en las pestaÃ±as de Excel
- Analizar mÃ©tricas de rendimiento por device
- Identificar patrones en las imÃ¡genes descargadas
- Tomar decisiones sobre inclusiÃ³n en dataset

## ğŸ”’ Seguridad

### Credenciales Seguras

- **Variables de entorno** para DB (archivo `.env`)
- **Archivos JSON separados** para servicios complejos
- **ExclusiÃ³n completa** del control de versiones
- **Conexiones de solo lectura** para todas las fuentes

### Archivos Protegidos (en .gitignore)

```text
.env                          # Variables de entorno
config/credentials/           # Directorio de credenciales
logs/                         # Archivos de log
output/                       # Archivos de salida
venv/                         # Entorno virtual
```

## ğŸš¨ Problemas Comunes

### Problemas Comunes

**Error de credenciales:**

```bash
python main.py status  # Verificar configuraciÃ³n
```

**Proceso activo no encontrado:**

```bash
python main.py active-process  # Ver estado actual
```

**ImÃ¡genes no se descargan:**

- Verificar credenciales de S3
- Comprobar que hay referencias/devices marcados con `revisar_imagenes=si`
- Usar `--dry-run` para simular primero

**Excel estÃ¡ abierto:**

- Cerrar archivo Excel antes de ejecutar comandos
- El sistema intentarÃ¡ 3 veces y crearÃ¡ backup si es necesario

### Logs y DiagnÃ³stico

Los logs detallados se guardan en:

- `output/processes/{process_name}/logs/`
- Console output con timestamps
- Logs especÃ­ficos por comando ejecutado

## ğŸ“‹ Requisitos

- **Python 3.8+** (verificado automÃ¡ticamente)
- **Acceso a Elasticsearch** con datos de inferencia
- **Acceso de lectura a MySQL** con tablas de referencia
- **Credenciales de AWS S3** para descarga de imÃ¡genes
- **Espacio en disco** para imÃ¡genes (aprox. 10MB por device/referencia)
- **ConexiÃ³n a internet** estable

## ğŸ”„ Cambios Clave

| FunciÃ³n | Estado |
|---------|--------|
| Renombrado `crear_dataset` â†’ `create_dataset` | âœ… |
| `review_devices` integrado en `review_images` | âœ… |
| Nuevos: `folder_structure`, `merge_datasets`, `summary_dataset`, `register_dataset` | âœ… |
| Progreso ZIP y subida S3 en registro | âœ… |
| Subida opcional de `datasets.csv` a S3 | âœ… |
| Manejo de Excel corrupto / permisos (logs y merges) | âœ… |
| Columnas enriquecidas (origen, dataset_original, relative_folder, filename) | âœ… |

## ğŸ› ï¸ Desarrollo

Para desarrollo:

```bash
# Clonar repositorio
git clone <repository_url>
cd ops_gFresh_dataset_training

# Configurar entorno de desarrollo
python setup.py
.\venv\Scripts\activate

# Instalar en modo desarrollo
pip install -e .

# Ejecutar pruebas
python -m pytest tests/ -v
```

### ExtensiÃ³n

- Usar `ProcessAwareSettings` para configuraciÃ³n
- Implementar logging con `ProcessLoggerManager`
- Seguir patrÃ³n de carpetas por proceso
- Documentar cambios en README

---

---
Autor: Alberto GÃ³mez Â· VersiÃ³n 2.1.0 Â· Agosto 2025

## ğŸ—‚ï¸ PublicaciÃ³n en GitHub

```bash
git init
git add .
git commit -m "Initial cleaned version"
git branch -M main
git remote add origin git@github.com:TU_ORG/ops_gfresh_dataset_manager.git
git push -u origin main
```

Listo.
